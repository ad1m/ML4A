<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>ML</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
    <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
  </head>
  <body>

    <style>
    #right_div {
    float: right;
    border: 0px solid black;
    text-align: center;
}
</style>


    <section class="page-header">
      <br>
      <br>
      <h1 class="project-name">Machine Learning</h1>
      <span></span>
      <!--<h2 class="project-tagline">Part 1: Motivation, History, Theory, & Application</h2>-->
      <h3 class="project-tagline">By: Adam Lieberman</h3>
      <br>
      <br>
      <!--<a href="#" class="btn">View on GitHub</a>
      <a href="#" class="btn">Download .zip</a>
      <a href="#" class="btn">Download .tar.gz</a> -->
    </section>

    <section class="main-content">
    <h1>Definition</h1>
    <p>Machine Learning is a method of teaching computers to make and improve predictions, or behaviors based on some provided dataset. It gives computers the ability to learn without being explicitly programmed.</p>
    <blockquote>Machine Learning is in essence computational statistics. It is the broader notion of building computational artifacts that learn over time based on experience. It is the math, science, engineering, and computing behind building these artifacts <br>&nbsp&nbsp- Michael Littleman & Charles Isbell</blockquote>
    <p>Essentially, machine learning allows computers to look at a set of data, learn from it, make predictions on new data, and in some cases continually improve predictions over time.</p>
    <h1>Types of Machine Learning</h1>
    <p>There are three main types of Machine Learning:</p>
    <ul>
    <li><b>Supervised Learning</b> - For every input in the dataset there is a corresponding target or label for that input. After training, the supervised learning algorithm will be able to provide a target for any new input. Supervised learning seeks a function from inputs to the respective rargets. If the domain of the targets is in the form of classes the supervised learning problem is a classification problem. An example of classification could be handwriting digit recognition. Here we would have an image $x$ as our input and a digit $y$ as the corresponding target. We see that this is a classification problem because each new input that we query can only be assigned a target of digits 0-9. If the target domain is conntinuous then the supervised learning problem is a regression problem. An example of a regression problem is predicting the stock market. We have some features for our stock as the input and the next day's price. We can then try and query the closing features of the current day to try and predict the price tomorrow. We see that this is a regression problem because we have a continuous domain, the predicted price could be for instance 32.58 or 198.21 or any number between 0 and infinity. In essence, we can call supervised learning function approximation.
    <br><br>
    Example 1: Say we have the following inputs: [1,2,3,4,5,6,7,8] and the following target outputs [1,4,9,16,25,36,49,64]. We could learn this function approximation as $f(i) = t$ where $i$ is the input value and $t$ is the target. Now, we might ask if the input is 10 what is the output? Well, if our learned function $f$ was $f(i) = i^2$ then we would have $f(10) = 10^2 = 100$. We see that this problem is a supervised regression problem. 
    <br><br>
    Example 2: Say we have some input images of cats and dogs along with some binary label. If the target label is 0 it is a cat. If the target label is 1 the image is a dog. We extract some features from the images. We can then learn a function $f$ from the inputs $i$. Then, for instance, if $f(i) >= 0.5$ the image is a cat. If $f(i) < 0.5$ then the image is a dog.
    </li>
    <br>
    <li><b>Unsupervised Learning</b> - Our dataset consists of only inputs with no corresponding targets. Here we seek to find the structure or relationships between different inputs. Unsupervised learning is commonly used for clustering where similar inputs are grouped together in clusters. Then, any new input can be assigned an appropriate cluster. Additionally, unsupervised learning can be used for anomaly detection to detect outliers in the dataset that do not conform to an expected pattern. It can also be used for dimensionality reduction where we can get a more simple, or lower dimensional represnetation, of high-dimensional datapoints by projecting them into a lower-dimensional space. We see that with unsupervised learning there is no precise question and answer in general like we have with supervised learning. We can, in essence, say that unsupervised learning is summarization, a concise description of our data.
    <br><br>
    Example 1: Say we have a bunch of images of people's faces as out input and we have no target. We decide that we want to cluster the facial images. We see that we have a unsupervised clustering problem. Since we do not have any target values we need to learn the representations from the data. We might decide that we cluster by gender. We could cluster by ethnicuty. We could cluster by hair color or eye color. There are many different ways that we could cluster the facial image data. The important thing is we decide how certain images belong with certain images and other images belong with other images since we do not have any lables that tell us how the pictures should be grouped together. We could find that there were 100 males and 75 females or there were 38 people with beards and 137 people without beards.
    <br><br>
    Example 2: Say we have a bunch of inputs that are of dimension 15,000. Say we have millions of these inputs. Due to the high dimension this would take our machine learning algorithm a long time to run. What if there was a way we could obtain a dimension of 1,000 while preserving the structure of our original 15,000 dimension dataset? We can do this! We could use unsupervised learning to reduce the dimension to a more managable dimension of 1,000, which preseved the structure of our features using a dimensionality reduction algorithm.
    <br><br>
    Note: We could use unsupervised learning to help us perform supervised learning. For instance say we have some images with labels as male or female. We could get the pixels of the images and use unsupervised learning to get some summaries of the pixels. We could then use these summaries as input to a supervised learning model to get our function approximation. The pipeline would look as follows:<br>
    <center>pixels $\rightarrow$ unspervised learning $\rightarrow$  summaries $\rightarrow$ supervised learning $\rightarrow$ labels</center>
    </li>
    <br>
    <li><b>Reinforcement Learning</b> - Reinforcement learning is learning from delayed reward. Here, the machine (our agent) learns from experience where feedback is given on an action our agent makes. The goal here is for the agent to act in the world so that its rewards are maximized. It can only do so by learning a sequence of actions that lead to this long-term reward. The agent learns this sequence by interacting with the environment and observing the rewards in every state.<br><br>
    Example: Our computer is playing the 2D game Pac-Man. Here the state is represented by the world PacMan lives in and the surrounding items such as the dots, enemies, walls, etc. The action is moving through the 2D space: moving left, right, up, or down. Our computer is playing as PacMan, which is called our agent. The agent, given the current state of the game world, needs to pick the best action to maximize rewards. Everytime the agent makes a move a score based on the state and action can be calculated which can trigger if the agent's move was "good" or "bad". We can learn from this delayed feedback to improve our agent overtime and make it better at playing PacMan.</li>
    </ul>
    <h1>Data Importance</h1>
    <p>Before moving forward, it is imperative to note the key importance data plays in the world of machine learning. The machine learning algorithm relies on the data that is provided to it. If you train a machine learning algorithm on a very small and incoherent dataset, the machine learning algorithm will not perform as expected when it is queryed with new information. Obtaining as much data as possible and maintining and using a high quality dataset can greatly make predictions more accurate as our algorithm can model the world of the data better.
    <h1>Cleaning Data</h1>
    <h1>Feature Generation</h1>
    <h1>Feature Extraction</h1>
    <h1>Train/Test Split</h1>
    <p>With regards to our data, we need to split it up into a training and testing set. We do this because we need to expose our machine learning algorithm to some data so that it can learn from it, but we also need to keep a separate set that the algorithm has not seen so that we can evaluate the performance of the machine learning algorithm. We call the data that the machine learning algorithm trains on the training set and we call the data held out to test the machine learning algorithm the test set. The training and testing set should not be the same, otherwise our machine learning model cheats when we evaluate it because it has seen the test data before since it was trained on the specific test set. We would like the testing set to include lots of examples which are not found in the training set. We want our machine learning algorithm to be able to generalize so that we can query it with novel samples and get an accurate result. For instance, in school your teacher might teach you a lesson and give you some sample questions for a test. If the test consists of only the sample questions she gave you before the test then you will probably get a 100% just from memorization. For her to see that you have learned she creates the test from questions which she has not given you on the sample test. 
    <br><br>
    Example: We have a dataset consisting of the square feet of a home and the price of the home. We want to predict the price of a house given the square feet. Here we have a supervised regression problem.
    <center><table>
      <tr>
    <th>Square Feet</th>
    <th>Price</th> 
  </tr>
  <tr>
    <td>1000</td>
    <td>120000</td> 
  </tr>
  <tr>
    <td>1100</td>
    <td>131500</td> 
  </tr>
  <tr>
    <td>2000</td> 
    <td>219000</td>
  </tr>
  <tr>
    <td>855</td>
    <td>99595</td> 
  </tr>
  <tr>
    <td>2100</td>
    <td>275000</td> 
  </tr>
  <tr>
    <td>3500</td>
    <td>595600</td> 
  </tr>
  <tr>
    <td>2800</td>
    <td>375000</td> 
  </tr>
  <tr>
    <td>2920</td>
    <td>415000</td> 
  </tr>
  <tr>
    <td>1750</td>
    <td>200000</td> 
  </tr>
  <tr>
    <td>2750</td>
    <td>335000</td> 
  </tr>
    </table></center>
    <p>We need to train the algorithm so we choose 80% of the data (8/10) samples to train the model. We can then use the remaining 20% (2/10) of the samples to test the model to see how well our model predicted the test data. Here, the choosing of the data can be random if our data is not time series data such as stock price data. We note that we keep both the features and the corresponding labels for our training and testing sets if we have a supervised learning problem. If we have an unsupervised learning problem then our train and test set do not contain the labels as we have no lables so only the features are present in the test sets.</p>
    </p>

    <center><h1><u>Part 1: Supervised Learning</u></h1></center>
    <h1>Terminology</h1>
    <ul>
    <li><b>Instances</b> - The set of input data that we have, for instance the pixels of images.</li>
    <li><b>Concept</b> - The function $f$ that maps the inputs (instances) to the outputs. The concept takes an item in the input space and maps it to somethign in the target space.</li>
    <li><b>Target Concept</b> - This is what we are trying to find, the answer. It is the particular function that we are looking for to map the inputs to the outputs. For example, a function that determines whether a picture is male or not is the target concept.</li>
    <li><b>Hypothesis Class</b> - The set of all concepts that we are willing to entertain, all the functions that we are willing to think about.</li>
    <li><b>Sample</b> - This is the training set.</li>
    <li><b>Candidate</b> - A concept that we think might be the target concept. Here, we assert a particular function that looks for the output. For instance, if our image sample has short hair then the image is male.</li>
    <li><b>Testing Set</b> - Our set of test data.</li>
    </ul>



    <h1>References:</h1>
    <li>Types of Machine Learning - https://www.quora.com/What-is-the-difference-between-supervised-and-unsupervised-learning-algorithms</li>
    <li>Examples of types of Machine Learning - http://ipython-books.github.io/featured-04/</li>
    <li>Reinforcement Learning PacMac Example: http://stackoverflow.com/questions/37973108/deep-reinforcement-learning-vs-reinforcement-learning</li>
    </section>


  </body>
</html>
